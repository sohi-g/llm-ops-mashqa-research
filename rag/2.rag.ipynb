{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f94e97-7e58-4253-9376-73af6f36e139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b85b61ff0c46fca6ce00b13bfeedea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca7b29ccf2246d9909a692ce5be7c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f093ae356904c4e8fa16b388e54aa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7c060b99374ee6846d90276b89e266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb34483ef08a4df990db7591da2df392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1e864dd3b844b783ac60feb1392c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90769ad87c6b459ba252eb3f6fb2d576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed864cc938a408587cff331a19c7491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f700070878ff4895b021a86b69c4291c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc7495b7bb54e16a4904279d8740d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385778844a9e4c06bb9ff819b6b40d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "# bitsandbytes parameters\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Set up quantization config\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# Load pre-trained config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c613429-9e6c-4a1e-bc9c-579eb152434b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c859dd05-9114-42f1-81f2-52a28b7efdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34347b17-ba1a-4c5d-9ae4-60a5068c03fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json \n",
    "def extract_data(data):\n",
    "    # Initialize empty lists to store extracted data\n",
    "    contexts = []     # Store contexts from paragraphs\n",
    "    questions = []    # Store questions from Q&A pairs\n",
    "    answers = []  # Store lists of answers corresponding to questions\n",
    "    ids = []        # Store IDs of questions\n",
    "    \n",
    "    # Loop through the provided data\n",
    "    for row in data:\n",
    "        # Extract paragraphs within the data\n",
    "        for paragraph in row['paragraphs']:\n",
    "            # Extract Q&A pairs within each paragraph\n",
    "            for qas in paragraph['qas']:\n",
    "                # Store context for each Q&A pair\n",
    "                contexts.append(paragraph['context'])\n",
    "                \n",
    "                # Store the question itself\n",
    "                questions.append(qas['question'])\n",
    "                \n",
    "                # Store all answers related to the question\n",
    "                answer_texts = []\n",
    "                for answer in qas['answers']:\n",
    "                    answer_texts.append(answer['text'])\n",
    "                answers.append(answer_texts)\n",
    "                \n",
    "                # Store the ID of the question\n",
    "                ids.append(qas['id'])\n",
    "    \n",
    "    # Return the extracted data\n",
    "    return contexts, questions, answers, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fcc222-f0dd-492f-aed9-dd7bd4900cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "path = \"data/train_webmd_squad_v2_full.json\"\n",
    "def load_data(path):\n",
    "    # Load JSON data from the given path\n",
    "    obj = json.load(open(path))\n",
    "    \n",
    "    # Extract the 'data' field from the loaded JSON object\n",
    "    obj = obj['data']\n",
    "    \n",
    "    # Process the extracted data to get context, question, answers, and IDs\n",
    "    context, question, answers, ids = extract_data(obj)\n",
    "    \n",
    "    # Create a Dataset object using the processed data\n",
    "    data = Dataset.from_dict({\n",
    "        'context': context,\n",
    "        'question': question,\n",
    "        'answer': answers,\n",
    "        'id': ids\n",
    "    })\n",
    "    \n",
    "    # Return the constructed Dataset object\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a5d0be-36ee-40f9-8963-0ccc4e243f49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import Language\n",
    "\n",
    "# Load data using the load_data function\n",
    "data = load_data(path)\n",
    "\n",
    "# Create a loader instance\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    path,\n",
    "    parser=LanguageParser( parser_threshold=500),  # Adjust parser settings as needed\n",
    ")\n",
    "\n",
    "# Load the documents\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27388ad5-02c9-45f9-950e-804bb5039b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140741"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e013ab3a-caab-4ac0-b6d4-1f3988741717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afefe6919fb424b852499b180722bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12354ce67762417f8f91e1b0f17fc0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d149ea6cc8549c0918e6b82452707f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3658e47e9942d7ae5f47aa9ec2accb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdc0143443249f886b91fcf59472b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c2b4292267434693e5c4eea1fa8f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b91367556a34f9198f32cfcc8fc286d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6722e3ebec455a91c1f695d7100219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0c3f8ff7214b4e82db6505349933ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67149249e99245a09447e3d6e027aa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04fd3808c304b0cbb75428e19b26984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfcc1b3c4bf471682a3465451a8cc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c1decfe2d44dca8e47471661dce065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861936ca0385493dad4ab949be873d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5f5927f2b047b285d170cfa589fe68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74f1738b85445dd8746dca370b6080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0385bd2e03a4eafb0db910f378a1676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d004565c7e4c09a3f2a848c2d573d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-large\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74d6843-36dd-4944-a5a6-5f87c31bd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2aa466-668c-49b7-9012-f43b4cf38bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 10min 46s, sys: 42.8 s, total: 1h 11min 29s\n",
      "Wall time: 1h 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd688c2-25ac-4d65-88c6-635f9c95ada4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<s>[INST] <>\n",
    "Act as a Multiple Answer Spans Healthcare Question Answering helpful assistant and answer the user's questions in details with reasoning. Do not give any false information. In case you don't have answer, specify why the question can't be answered.\n",
    "<>\n",
    "\n",
    "{context}\n",
    "\n",
    "{question} [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc2b1a8-14c5-4d50-ba53-e1071290488b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ce3238-9b0a-4a66-9003-306920eb7184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=mistral_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2450c87-c020-4fbe-8512-ce8cdba6b5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 37.5 ms, total: 18.5 s\n",
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What types of exercise are best for people with asthma?',\n",
       " 'result': \"\\nPeople with asthma can generally participate in most types of exercise, but it's important to choose activities that are appropriate for their individual needs and limitations. Short, intermittent periods of exertion, such as volleyball, gymnastics, baseball, walking, and wrestling, are generally well tolerated by people with exercise-induced asthma. Long periods of exertion, like soccer, distance running, basketball, and field hockey, may be less well tolerated, as are cold weather sports like ice hockey, cross-country skiing, and ice skating. However, many people with asthma are able to fully participate in these activities.\\n\\nSwimming is another good option for people with asthma, as it is a low-impact activity that can help improve cardiovascular fitness and lung function. It's also a great way to cool off during hot summer days.\\n\\nIt's important to note that people with asthma should always consult with their healthcare provider before starting any new exercise routine. They may need to take steps to manage their asthma symptoms while exercising, such as using an inhaler or taking medication beforehand. Additionally, people with asthma should avoid exercising outdoors when pollen counts are high (if they have allergies) and also avoid exercising outdoors when there is high air pollution. They should also restrict exercise when they have a viral infection and exercise at a level that is appropriate for them.\",\n",
       " 'source_documents': [Document(page_content='that involve short, intermittent periods of exertion, such as volleyball, gymnastics, baseball, walking, and wrestling, are generally well tolerated by people with exercise-induced asthma. Activities that involve long periods of exertion, like soccer, distance running, basketball, and field hockey, may be less well tolerated, as are cold weather sports like ice hockey, cross-country skiing, and ice skating. However, many people with asthma are able to fully participate in these activities. Swimming, which', metadata={'source': 'data/train_webmd_squad_v2_full.json'}),\n",
       "  Document(page_content='exercise indoors or wear a mask or scarf over your nose and mouth. Avoid exercising outdoors when pollen counts are high (if you have allergies), and also avoid exercising outdoors when there is high air pollution. Restrict exercise when you have a viral infection. Exercise at a level that is appropriate for you. Again, asthma should not be used as an excuse to avoid exercise. With proper diagnosis and treatment of asthma, you should be able to enjoy the benefits of an exercise program without experiencing', metadata={'source': 'data/train_webmd_squad_v2_full.json'})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = qa_chain(\n",
    "    \"What types of exercise are best for people with asthma?\"\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901e45ee-375d-4a45-8eb1-1bf5da6f8053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People with asthma can generally participate in most types of exercise, but it's important to choose activities that are appropriate for their individual needs and limitations. Short, intermittent periods of exertion, such as volleyball, gymnastics, baseball, walking, and wrestling, are generally well tolerated by people with exercise-induced asthma. Long periods of exertion, like soccer, distance running, basketball, and field hockey, may be less well tolerated, as are cold weather sports like ice hockey, cross-country skiing, and ice skating. However, many people with asthma are able to fully participate in these activities.\n",
      "\n",
      "Swimming is another good option for people with asthma, as it is a low-impact activity that can help improve cardiovascular fitness and lung function. It's also a great way to cool off during hot summer days.\n",
      "\n",
      "It's important to note that people with asthma should always consult with their healthcare provider before starting any new exercise routine. They may need to take steps to manage their asthma symptoms while exercising, such as using an inhaler or taking medication beforehand. Additionally, people with asthma should avoid exercising outdoors when pollen counts are high (if they have allergies) and also avoid exercising outdoors when there is high air pollution. They should also restrict exercise when they have a viral infection and exercise at a level that is appropriate for them.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94899347-8a23-4260-a259-e6444b37874f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obsessive-compulsive disorder (OCD) is typically diagnosed based on a combination of self-reported symptoms and clinical evaluation by a mental health professional. The Diagnostic and Statistical Manual of Mental Disorders (DSM-5) provides specific criteria for diagnosing OCD, which include the presence of obsessions and compulsions that are intrusive, unwanted, and cause significant distress or impairment in daily life.\n",
      "\n",
      "To diagnose OCD, a mental health professional will typically conduct a thorough interview with the individual to assess their symptoms and gather information about their medical history, family history, and other relevant factors. They may also administer standardized questionnaires or tests to help evaluate the severity and duration of the individual's symptoms.\n",
      "\n",
      "It is important to note that a diagnosis of OCD requires a comprehensive evaluation by a qualified mental health professional, and self-diagnosis should not be relied upon. Additionally, it is possible for individuals with OCD to experience co-occurring disorders, such as anxiety or depression, which may need to be addressed as well.\n",
      "CPU times: user 13.1 s, sys: 2.15 ms, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = qa_chain(\n",
    "    \"How is obsessive-compulsive disorder diagnosed?\"\n",
    ")\n",
    "print(result[\"result\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00eb877-5719-4d3c-88ed-05f5a9936b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A blood clot is more likely to occur when an individual is immobile for extended periods of time, such as during bed rest or sitting for long periods of time. Additionally, being pregnant or having recently given birth, being overweight, smoking, and using birth control pills or hormone replacement therapy can also increase the risk of developing a blood clot. It's important to note that blood clots can occur in anyone, regardless of age or health status, although they are less common in younger, healthy individuals.\n",
      "CPU times: user 6.13 s, sys: 19.4 ms, total: 6.15 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = qa_chain(\n",
    "    \"When are you more likely to get a blood clot?\"\n",
    ")\n",
    "print(result[\"result\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524ea892-a407-4981-b7dc-a14721c493bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prevent back pain when lifting objects, it is important to follow these steps:\n",
      "\n",
      "1. Bend your knees and squat, pulling in your stomach muscles.\n",
      "2. Keep your back straight and avoid bending forward at the waist.\n",
      "3. Use your leg muscles to lift the object, rather than your back.\n",
      "4. If necessary, carry several small loads instead of one large one, or use a cart.\n",
      "5. Avoid reaching over your head and try to keep your arms close to your body.\n",
      "6. Use long-handled tools to reach high shelves or objects.\n",
      "7. Store items lower to reduce strain on your back.\n",
      "8. Take breaks frequently and stretch your back muscles regularly.\n",
      "9. Maintain good posture throughout the day, even when sitting or standing.\n",
      "10. Consider using ergonomic equipment or furniture to reduce stress on your back.\n",
      "CPU times: user 10.6 s, sys: 2.46 ms, total: 10.7 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = qa_chain(\n",
    "    \"How should you lift objects to prevent back pain?\"\n",
    ")\n",
    "print(result[\"result\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9f0c9c3-9bc5-4c06-a450-617503f17f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be smart with antibiotics, it is important to understand their proper use and follow guidelines issued by healthcare professionals. This includes taking antibiotics only when necessary for a bacterial infection, using them as prescribed, taking all of the antibiotics as directed, and not sharing antibiotics with others. Additionally, preventing the spread of germs through good hygiene practices such as washing hands regularly, covering your mouth and nose when coughing or sneezing, and avoiding close contact with sick individuals can also help reduce the need for antibiotics. It is also important to note that antibiotics should not be used to treat viral infections such as the common cold or flu.\n",
      "CPU times: user 8.19 s, sys: 10.9 ms, total: 8.2 s\n",
      "Wall time: 8.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = qa_chain(\n",
    "    \"How can you be smart with antibiotics?\"\n",
    ")\n",
    "print(result[\"result\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feecfe9-3c8e-4031-94c7-837a57b82adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
